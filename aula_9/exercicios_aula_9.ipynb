{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 9\n",
    "# Resampling e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cross-validation\n",
    "Para esse exercício, usaremos uma base de dados das candidaturas à Câmara dos Deputados em 2014 que contém, entre outros, variáveis como o sexo, a raça, a escolaridade e o status de reeleição das candidaturas, bem como uma dummy (resultado) que indica se a candidatura foi () ou não () eleita (Machado, Campos, e Recch 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/FLS-6497/datasets/main/aula9/camara_2014.csv'\n",
    "dados = pd.read_csv(link, sep=';', decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Básico\n",
    "Crie uma pipeline para estandardizar variáveis numéricas (ou transformar variáveis categóricas em dummies) com algum modelo de classificação da sua escolha e o valide usando K-fold com k=5 e, depois, com k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.04988265, 0.0330739 , 0.04088688, 0.03407478, 0.01881862]), 'score_time': array([0.0060091 , 0.        , 0.        , 0.00299692, 0.        ]), 'test_score': array([0.60550459, 0.61842105, 0.54320988, 0.69736842, 0.46938776])}\n",
      "{'fit_time': array([0.02438021, 0.03300786, 0.02688622, 0.04741144, 0.03405905,\n",
      "       0.05072284, 0.05769563, 0.05773497, 0.04764009, 0.03243589]), 'score_time': array([0.        , 0.        , 0.        , 0.00202632, 0.00051212,\n",
      "       0.00410867, 0.00784063, 0.        , 0.00705457, 0.        ]), 'test_score': array([0.56896552, 0.6185567 , 0.57894737, 0.66666667, 0.56198347,\n",
      "       0.57142857, 0.73972603, 0.64935065, 0.46808511, 0.51851852])}\n"
     ]
    }
   ],
   "source": [
    "# o que acontece quando passamos variáveis numéricas para o OneHotEncoder?\n",
    "y = dados.resultado\n",
    "cat_cols = dados.columns[~dados.columns.isin(['resultado', 'receita_proc_ln'])]\n",
    "dados_cat = dados[cat_cols]\n",
    "dados_cat = OneHotEncoder().fit_transform(dados_cat)\n",
    "dados_num = dados[['receita_proc_ln']]\n",
    "X = hstack([dados_cat, dados_num])\n",
    "\n",
    "def cross_validate_kfold_logreg(k):\n",
    "    kf = KFold(n_splits=k)\n",
    "    logreg = LogisticRegression()\n",
    "    return cross_validate(logreg, X, y, cv=kf, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03463507, 0.04138041, 0.03198671, 0.0322566 , 0.02407622]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([0.60550459, 0.61842105, 0.54320988, 0.69736842, 0.46938776])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_kfold_logreg(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.05629539, 0.04067302, 0.04954863, 0.04501462, 0.05291629,\n",
       "        0.05189085, 0.05719256, 0.04808998, 0.05654693, 0.04931712]),\n",
       " 'score_time': array([0.00799918, 0.00820661, 0.00228453, 0.0079999 , 0.00052094,\n",
       "        0.        , 0.00800753, 0.        , 0.        , 0.        ]),\n",
       " 'test_score': array([0.56896552, 0.6185567 , 0.57894737, 0.66666667, 0.56198347,\n",
       "        0.57142857, 0.73972603, 0.64935065, 0.46808511, 0.51851852])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_kfold_logreg(k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) LOO\n",
    "Sorteie apenas algumas observações do banco completo (50, por exemplo) e, em vez de usar K-fold, desta vez use LOO como estratégia de validação (no mlr3, a função chama-se loo; no sklearn, LeaveOneOut).1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o que acontece quando passamos variáveis numéricas para o OneHotEncoder?\n",
    "dados_sample = dados.sample(100)\n",
    "y_sample = dados_sample.resultado\n",
    "cat_cols = dados_sample.columns[~dados.columns.isin(['resultado', 'receita_proc_ln'])]\n",
    "dados_sample_cat = dados_sample[cat_cols]\n",
    "dados_sample_cat = OneHotEncoder().fit_transform(dados_sample_cat)\n",
    "dados_sample_num = dados_sample[['receita_proc_ln']]\n",
    "X_sample = hstack([dados_sample_cat, dados_sample_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "logreg = LogisticRegression()\n",
    "resultados = cross_validate(logreg, X_sample, y_sample, cv=loo, scoring='accuracy')\n",
    "resultados = pd.DataFrame(resultados)\n",
    "resultados.test_score.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Mantendo balanço\n",
    "Na base de dados, há muito menos candidaturas eleitas do que não-eleitas. Para evitar que amostras de treino e de teste percam esse balanço original, use K-fold estratificado (no mlr3, basta declarar stratum = variavel na task; no sklearn, use StratifiedKFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001E3AA042C70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Repetindo o processo\n",
    "Finalmente, use repeated k-fold para minimizar a variação decorrente do sorteio no particionamento das amostras (no mlr3, com repeated_cv; no sklearn, com RepeatedKFold ou com RepeatedStratifiedKFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow de validação\n",
    "Para este exercício, precisaremos separar a nossa amostra de uma forma mais próxima daquela usada em projetos reais: treino, teste e validação. Para tanto:\n",
    "\n",
    "## a) Holdout\n",
    "Faça um holdout inicial da base, separando 90% dela para treino e teste e 10% para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Cross-validation\n",
    "Com os 90% restanted da base, treine e valide um modelo usando alguma estratégia de cross-validation. Ao final, quando encontrar o melhor modelo, treine ele em todos os 90% das observações e o valide na base de validação com 10% de observações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando mais dados\n",
    "Neste exercício, vamos voltar à base de dados climático de São Bernardo do Campo e, com o que aprendemos nas últimas aulas, vamos tentar melhorar nosso desempenho na tarefa de predizer temperatura máxima diária. Carregue a base com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jacobwright32/Web_Scraper_AI_Core_Project/bb4865ae568e23ab8fadb6ea58cf117df2164ef3/web%20scraping/Cleaned%20Data/Brazil_Sao%20Bernardo%20Do%20Campo_Cleaned.csv'\n",
    "dados = pd.read_csv(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Novo workflow\n",
    "Monte um workflow para melhorar o desempenho na tarefa de predizer maximum_temprature. Em particular, considere o seguinte:\n",
    "\n",
    "Pré-processar variáveis contínuas (minmax ou estandardização);\n",
    "Reduzir dimensionalidade (PCA ou kernelpca);\n",
    "Considerar combinações não-lineares (criando polinômios ou usando MARS)\n",
    "Usar ensemble, inclusive com stacking\n",
    "Usar uma estratégia de validação que deixe mais dados para treino (K-fold com um  ou )\n",
    "Considerar a estrutura temporal dos dados (é possível criar uma variável lag de maximum_temprature, o transformar o problema em um de série temporal e usar walk-forward validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3446cf101c0afad7039eefd5672a1d4819703149d96c9c2c72d5750774bc760c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
