{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:12.683749Z",
     "start_time": "2022-10-05T18:41:09.663284Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pyearth import Earth\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:12.817294Z",
     "start_time": "2022-10-05T18:41:12.688256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carrega dados e separa as amoastras\n",
    "link = 'https://raw.githubusercontent.com/jacobwright32/Web_Scraper_AI_Core_Project/bb4865ae568e23ab8fadb6ea58cf117df2164ef3/web%20scraping/Cleaned%20Data/Brazil_Sao%20Bernardo%20Do%20Campo_Cleaned.csv'\n",
    "dados = pd.read_csv(link).select_dtypes(['number'])\n",
    "\n",
    "y = dados['maximum_temprature']\n",
    "X = dados.loc[:, dados.columns != 'maximum_temprature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Criação de pipelines** Usando pipelines, crie três diferentes pré processamentos para as features numéricas da base: a) uma sem transformações, b) outra fazendo estandardiazação das variáveis e c) outra incluindo alguns polinômios. As pipelines devem usar regressão linear simples como modelo para predizer a variável maximum_temprature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:12.855838Z",
     "start_time": "2022-10-05T18:41:12.819791Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rmse_reg():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "    return mean_squared_error(Y_test, reg.predict(X_test))\n",
    "\n",
    "get_rmse_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:12.894953Z",
     "start_time": "2022-10-05T18:41:12.858750Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rmse_scale_reg():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Cria uma pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('lm', LinearRegression())\n",
    "        ])\n",
    "\n",
    "    # Treina o modelo, calcula o RMSE\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    \n",
    "    return mean_squared_error(Y_test, pipe.predict(X_test))\n",
    "    \n",
    "get_rmse_scale_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:12.942870Z",
     "start_time": "2022-10-05T18:41:12.900241Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rmse_scale_poly_reg():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Cria uma pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(2)),\n",
    "        ('lm', LinearRegression())\n",
    "        ])\n",
    "\n",
    "    # Treina o modelo, calcula o RMSE\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    \n",
    "    return mean_squared_error(Y_test, pipe.predict(X_test))\n",
    "\n",
    "get_rmse_scale_poly_reg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) **Benchmark** Compare as pipelines anteriores rodando 100 vezes cada uma usando holdout com 70% das observações em treino, calculando para cada também o RMSE. Reporte os resultados por meio de um gráfico de boxplot. Dica: use uma função para encapsular pipelines, treino dos modelos e cálculo de métricas de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:14.884923Z",
     "start_time": "2022-10-05T18:41:12.945165Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse_reg = [get_rmse_reg() for i in range(100)]\n",
    "rmse_scale_reg = [get_rmse_scale_reg() for i in range(100)]\n",
    "rmse_scale_poly_reg = [get_rmse_scale_poly_reg() for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:15.059448Z",
     "start_time": "2022-10-05T18:41:14.887116Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse = pd.DataFrame({\n",
    "    'rmse_reg': rmse_reg,\n",
    "    'rmse_scale_reg': rmse_scale_reg,\n",
    "    'rmse_scale_poly_reg': rmse_scale_poly_reg\n",
    "})\n",
    "\n",
    "rmse = pd.melt(rmse, value_name='rmse', value_vars=['rmse_reg', 'rmse_scale_reg', 'rmse_scale_poly_reg'])\n",
    "\n",
    "sns.boxplot(data=rmse, x='variable', y='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **Comparação dos modelos** Selecione a melhor pipeline do exercício anterior e crie outras três novas em cima dela: uma que regressão por KNN em vez de regressão linear, uma que use MARS (o algoritmo earth); e, por fim, uma que use regressão por meio de árvore de decisão (tree ou regr.rpart). Rode 100 vezes cada pipeline e compare novamente od RMSE usando um gráfico boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:41:15.076157Z",
     "start_time": "2022-10-05T18:41:15.062793Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rmse_scale_poly_knn():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Cria uma pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(2)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "        ])\n",
    "\n",
    "    # Treina o modelo, calcula o RMSE\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    \n",
    "    return mean_squared_error(Y_test, pipe.predict(X_test))\n",
    "\n",
    "def get_rmse_scale_poly_mars():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Cria uma pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(2)),\n",
    "        ('mars', Earth())\n",
    "        ])\n",
    "\n",
    "    # Treina o modelo, calcula o RMSE\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    \n",
    "    return mean_squared_error(Y_test, pipe.predict(X_test))\n",
    "\n",
    "def get_rmse_scale_poly_tree():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Cria uma pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(2)),\n",
    "        ('tree', tree.DecisionTreeClassifier())\n",
    "        ])\n",
    "\n",
    "    # Treina o modelo, calcula o RMSE\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    \n",
    "    return mean_squared_error(Y_test, pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:42:04.527435Z",
     "start_time": "2022-10-05T18:41:15.082965Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse_scale_poly_knn = [get_rmse_scale_poly_knn() for i in range(100)]\n",
    "rmse_scale_poly_mars = [get_rmse_scale_poly_mars() for i in range(100)]\n",
    "rmse_scale_poly_tree = [get_rmse_scale_poly_tree() for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:42:04.708222Z",
     "start_time": "2022-10-05T18:42:04.528059Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse = pd.DataFrame({\n",
    "    'rmse_scale_poly_knn': rmse_scale_poly_knn,\n",
    "    'rmse_scale_poly_mars': rmse_scale_poly_mars,\n",
    "    'rmse_scale_poly_tree': rmse_scale_poly_tree\n",
    "})\n",
    "\n",
    "rmse = pd.melt(rmse, value_name='rmse', value_vars=['rmse_scale_poly_knn', 'rmse_scale_poly_mars', 'rmse_scale_poly_tree'])\n",
    "\n",
    "sns.boxplot(data=rmse, x='variable', y='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) **Validação** Usando a melhor *pipeline* encontrada no exercício anterior, faça validação nas seguintes bases de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:45:18.460614Z",
     "start_time": "2022-10-05T18:45:17.109880Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clima em Campinas\n",
    "campinas = 'https://raw.githubusercontent.com/jacobwright32/Web_Scraper_AI_Core_Project/bb4865ae568e23ab8fadb6ea58cf117df2164ef3/web%20scraping/Cleaned%20Data/Brazil_Sao%20Bernardo%20Do%20Campo_Cleaned.csv'\n",
    "campinas = pd.read_csv(campinas)\n",
    "campinas = campinas.select_dtypes(['number'])\n",
    "y_camp = campinas['maximum_temprature']\n",
    "X_camp = campinas.loc[:, dados.columns != 'maximum_temprature']\n",
    "\n",
    "# Clima em Southampton\n",
    "southampton = 'https://raw.githubusercontent.com/jacobwright32/Web_Scraper_AI_Core_Project/master/web%20scraping/Cleaned%20Data/United%20Kingdom_Southampton_Cleaned.csv'\n",
    "southampton = pd.read_csv(southampton)\n",
    "y_sh = southampton['maximum_temprature']\n",
    "X_sh = southampton.loc[:, southampton.columns != 'maximum_temprature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:45:22.904274Z",
     "start_time": "2022-10-05T18:45:22.834304Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) **Visualização** Usando os resultados da melhor *pipeline*, plote a relação entre predições e valores reais de `maximum_temprature` nas duas bases de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Árvores de decisão e *bag-of-words***\n",
    "\n",
    "Como vimos, pré-processamento deve ser aplicado *antes* de fazermos *split sample* de validação (i.e., criar amostras de teste e de treino). Agora, implemente um *workflow* que leva isso em conta. Para tanto, você deverá criar uma função que separe textos em treino e teste, que aplique pré-processamento apenas na amostra de treino e que, depois, replique ele na amostra de teste para, então, rodar um algoritmo e calcular alguma métrica de validação.\n",
    "\n",
    "\n",
    "Para esse exercício, será necessário carregar uma base de discursos presidenciais feitos por Dilma Rousseff e Michel Temer em parte de seus mandatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://github.com/FLS-6497/datasets/raw/main/aula5/discursos_presidenciais.csv'\n",
    "discursos = pd.read_csv(link, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também precisaremos fazer pré-processamento dos textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vct = CountVectorizer() # Ha mais hyperparametros\n",
    "X = vct.fit_transform(discursos.discurso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) *Pipelines***\n",
    "\n",
    "Usando *pipelines*, crie duas *pipelines* diferentes de pré-processamentos para as os discursos da base: a) uma que só mantenha termos que aparecem em pelo menos 20% dos documentos (ou ao menos em 20 documentos); outra igual a anterior que permita bi-gramas. As *pipelines* devem usar *Naive Bayes* como modelo para predizer a variável `planalto`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Benchmark**\n",
    "\n",
    "Rode cada *pipeline* 10 vezes, calculando o `F1` de cada predição do modelo na base de teste que tenha 20% dos discursos. Plote os resultados usando boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Modelos**\n",
    "\n",
    "Use a melhor *pipeline* para criar outra, que em vez de *Naive Bayes* use árvore de decisão (`classif.rpart`, no caso do `mlr3`). Rode 10 vezes cada uma, calcule e reporte o `F1` para cada uma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2200ae1c0cbe001e680a38cb6c644dc74d041778d89743de2e8d95f2bf1b5ba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
